\section{Литература}
\subsection{Нейронные сети}
Нейронная сеть представляет из себя последовательность слоев, которые трансформируют данные. Каждый слой состоит из нескольких вычислительных узлов определенного типа, называемых нейронами. Слои бывают разных типов, три базовых  -- полносвязные, сверточные, рекуррентыные. Выход каждого нейрона также преобразуется функцией активации.

Каждый нейрон хранит в себе веса, которые определяют непосредственно преобразование данных. Веса инициализируются случайно.
В обучении функция потерь, которая является мерой схожести предсказания сети и правильного ответа, минимизируется на обучающей выборке, которая содержит правильные предсказания (обучение с учителем). Минимизация происходит путем изменения весов в нейронах в процессе обратного распространения ошибки.

Искусственные нейронные сети показали себя как мощный инструмент машинного обучения и широко применяются во многих задачах.

{\bfseries DeepBind} -- предсказание связывания белка с последовательностью \cite{alipanahi_predicting_2015}.

В подходе DeepBind 927 отдельных моделей (среднее число параметров 1586) применялось для бинарного предсказания \emph{in vivo} и \emph{in vitro} афинностей связывания (то есть связывается или нет) для 538 транскрипционных факторов и 194 РНК-связывающихся белков.


{\bfseries DeepSEA} -- предсказание влияния некодирующих вариантов \cite{zhou_predicting_2015}.
 В данной работе рассматривается функциональный эффект вариантов, в том числе однонуклеотидных полиморфизмов (SNP), в контексте геномного окружения. 

На первой стадии сверточная нейронная сеть используется для предсказания 919 черт профиля хроматина из последовательности ДНК. Извлечение  информации происходит из нуклеотидного контекста размером 1000 пар нуклеотидов. Использовался контекст с обеих сторон, для каждой позиции результирующее предсказание вычислялось комбинацией. Предсказываются профили связывания транскрипционных факторов, сайты гиперчувствительности ДНКазы I, профили гистоновых меток. Далее предсказанная \emph{de novo} информация о хроматине используется в классификаторе на основе логистической регрессии для предсказания функционального эффекта.

Для обучения сети были использованы объединенные данные ENCODE и Roadmap Epigenomics projects. Оказалось, что нейронная сеть превосходит в точности предсказания один из лучших в этой области метод gkm-SVM, основанный на k-мерах \cite{ghandi_enhanced_2014}.

Нейронная сеть состоит из трех сверточных слоев, перемежающихся пулингом, полносвязного слоя и решающего слоя. В некоторых слоях использован dropout -- приравнивание заданной части выходных значений к нулю для избежания переобучения.

Суммарное число параметров модели составляет около 52 миллионов.



{\bfseries Basset} -- предсказание открытости хроматина -- физического упаковывания генетической информации (ДНК и ассициированные белки). Эта характеристика варьирует в разных типах клеток, поэтому не может быть полностью объяснена особенностями последовательности, так как в одном организме все клетки имеют одинаковый геном.
Предсказывает 164 бинаризированных характеристики доступности ДНК (около 4 миллионов параметров).



Одной из проблем сверточных нейроетей может быть невозможность в неглубокое архитектуре отловить дистантные взаимодействия. Одно из решений dilated convolution (прочитать)
Basenji – Sequential regulatory activity prediction across chromosomes with convolutional neural networks [github1][github2][biorxiv]

A follow-up project to Basset, this Tensorflow-based model uses both standard and dilated convolutions to model regulatory signals and gene expression (in the form of CAGE tag density) in many different cell types. Notably, the underlying model has been brought into Google's Tensor2Tensor repository (see "github2" link above), which collects many models in image and speech recognition, machine translation, text classification etc. However, at the time of writing the Tensor2Tensor model seems not quite mature for easy use, so it is probably better to use the dedicated Basenji repo ("github1") for now.

рассказать про рекуррентные немного.


DanQ: гибридная сверточная и рекуррентная глубокая сеть для оценки функции последовательностей  ДНК \cite{quang_danq:_2016}. 
Разработана для предсказания функции некодирующих ДНК из их последовательностей. Опирается на те же данные, что и DeepSEA.

Первые слои сети распознают и захватывают паттерны в последовательности -- сверточный слой и пулинг. После этого рекуррентный двунаправленный слой может улавливать далекие взаимодействия, которые обусловлены физическим ограничениями на взаимодействия частей ДНК из-за укладки хроматина. Содержит полносвязный и решающий слои нейронов.

DanQ превосходит DeepSEA по многим метрикам, представленным в статье. В этой нейронной сети впервые представлена архитектура, включающая сверточные и рекуррентные слои.


Внимание.

Modeling Enhancer-Promoter Interactions with Attention-Based Neural Networks [bioRxiv preprint][code]

The concept of attention in (recurrent) neural networks has become quite popular recently, not least because it has been used to great effect in machine translation models. This paper proposes an attention-based model for getting at the interactions between enhancer sequences and promoter sequences.


